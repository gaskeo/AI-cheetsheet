# Модель
`tensorflow.keras.models`

```
model.compile(optimizer, loss, metrics)         скомпилировать сеть
model.fit(x_train, y_train, epochs)             обучить сеть
model.evaluate(x_test, y_test)                  проверить на тестовой выборке
model.predict(one_elem)                         предсказать по 1 элементу
                                                размерность (1, (размерность самого элемента))
model.summary()                                 информация о модели
```

## `Sequential`
Простейшая полносвязная сеть. 
```
Sequential(
    layers: iterable    |   слои нейронной сети
)
```

# Слои
`tensorflow.keras.layers`

## `Dense` 
Самый простой полносвязный слой (каждый предыдущий нейрон связан с каждым следующим)
```
Dense(
    units: int          |   размерность выходного слоя
    activation: str     |   функция активации
    use_bias: bool      |   использование bias (t)
)
```

## `BatchNormalization`
Преобразует входные данные в числа от `-1` до `1`

## `Flatten`
Выравнивает входные данные до одной размерности: `(64, 10) -> (640, )`

## `Dropout`
Выключает случайные нейроны
```
Dropout(n: float)  n - какой процент нейронов надо отключить (0, 1)
```

## `Conv2D`
```
Conv2D(
    filters: int,           |   количество фильтров в слое 
                            |   (количество нейронов в нейронном слое)
                            
    input_shape: array,     |   только на входном слое, 
                            |   каждый пиксель оформлен отдельно:
                            |   (28, 28, 1) - картинка 28x28 + каждый пиксель - в своем массиве
                            
    kernel_size: iterable,  |   размер конволюционного фильтра (t)
                            |   (3, 3), (5, 5), ...
                             
    activation: str,        |   функция активации
    padding: str,           |   либо same, либо valid
                            |   same - на выходе такое же по размеру изображение
                            |   valid - края фильтра не заходят за края изображения, 
                            |       крайние пиксели обрезаются (размер фильтра // 2)
                            
    strides: int || tuple,  |   шаг прохода фильтра: прыжок между пикселями
                            |   если tuple: (x, y) - шаг по x, шаг по y 
)
```

## `MaxPool2D`
Слой для уменьшения размеров изображения за счет выбора из соседних пикселей пикселя с максимальным значением 
```
MaxPool2D(
    (2, 2)      |   размер окна, уменьшающего изображение
)
+---+---+
| 1 | 2 |                           +---+
+---+---+ ---> Max(1, 2, 5, 6) ---> | 6 |
| 5 | 6 |                           +---+
+---+---+

```

# Функции активации

## `Sigmoid`
Возвращает значения от `0` до `1`
* обычно применяется на выходном слое
* задача бинарной классификации (принадлежит/не принадлежит)

## `Relu`
Значения меньше нуля приравниваются к нулю
* обычно в скрытых слоях
* используется с картинками (`RGB`)

## `Tanh` - гиперболический тангенс
Более плавный по сравнению с `Sigmoid`

Возвращает значения от `-1` до `1`
* лучше работает со значениями, близкими к нулю
* можно использовать с картинками (`LAB` формат)

## `softmax`
Распределяет вероятность между классами
* обычно на последнем слое 
* в задачах классификации

# Функции ошибок

## `mae` - mean absolute error
Средняя абсолютная ошибка - среднее отклонение точки от предсказанного значения
* для регрессии

## `mse` - mean square error
Среднеквадратичная ошибка - отклонение в квадрате
* для регрессии

## `binary_crossentropy`
* для бинарной классификации для `[0, 1]`

## `categorical_crossentropy`
* для классификации, когда в выходном слое массив с индексом правильного элемента  

## `categorical_accuracy`
* для классификации

## `sparse_categorical_crossentropy`
* для классификации, когда в выходном слое только один нейрон с `id` класса

# Оптимизаторы `t`

## `adam`
Один из лучших оптимизаторов
```
optimizer = Adam(
    learning_rate=float[default: 10 ** -5]   |   шаг обучения
)
```


# callbacks
Коллбэки нужны для отслеживания состояния модели на эпохе

```
class MyCallBack(tf.keras.callbacks.Callback): 
    def on_epoch_end(self, epoch, logs): 
        if logs['loss'] < 90: 
            print('конец') 
            self.model.stop_training = True


model = ...
...
model.fit(..., callbacks=[MyCallBack()])
```


# Прочее


## `train_test_split`
Функция для деления выборки на тренировочную и тестовую
```
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(
    x: array,               |   масссив с данными
    y: array,               |   массив с ответами
    test_size: float,       |   процент в тестовой выборке [0, 1]
    train_size: float,      |   в тренировочной
    random_state: int,      |   random seed
    shuffle: bool           |   нужно ли перемешивать
)
```


## `plot_model`
Функция для представления схемы нейронной сети
```
from tensorflow.keras.utils import plot_model
plot_model(model, show_shapes=True)
```


## `to_categorical` 
Функция для представления значений по категориям 
```
from tensorflow.keras.utils import co_categorical
a = array(1, 5, 2, 5, 2)
to_categorical(a) -> 
-> array(
    [1, 0, 0],
    [0, 1, 0],
    [0, 0, 1],
    [0, 1, 0],
    [0, 0, 1]
)
```