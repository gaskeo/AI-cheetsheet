
# Линейная модель 


## Основные понятия
Линейная модель — функция, 
которая принимает на вход признаки объекта и отдает ответ

Линейная функция — функция, 
которую можно записать с помощью линейной комбинации вектора `x`:

![Линейная функция](images/img_2.png)

Или в сокращенном виде: 

![Линейная функция сокращенно](images/img_3.png)

## Плюсы
* Легко интерпретируемы 
## Минусы 
* Только для простых задач 
* Плохо работают с зависимыми признаками
* Сильно зависят от обучающей выборки 

## Линейная регрессия
Регрессионная модель зависимости одной переменной 
от одной или нескольких других

![Линейная регрессия](images/img_1.png)

## Функция риска
Пусть `L` - функция потерь на паре (loss):

![Функция потерь](images/img_4.png)

> Функция loss должна быть дифференцируема

Функция риска `Q(X)` — функция loss по всем объектам

![Функция потерь](images/img_5.png)

Для нахождения наилучших весов `w` нужно приблизить 
`Q(X)` к минимальному значению: 

![Функция риска стремится к нулю](images/img_6.png)

### В матричной форме

![Функция риска в матричном виде](images/img_7.png)

Где `Xw`: 

![Xw](images/img_8.png)

Сделав еще несколько преобразований, можно вывести формулу: 

![Формула функции риска](images/img_9.png)

## Вывод формулы оптимального нахождения весов `w`

Как было сказано ранее, чтобы найти оптимальные веса `w`,
нам нужно устремить `Q(X)` к минимальному значению: 

![Развернутая Q(X) стремится к нулю](images/img_10.png)

Чтобы найти минимальное значение `Q(X)`, 
нужно продифференцировать данную функцию:

![Производная Q(X)](images/img_11.png)

После приравнивания производной к нулю для получения точек экстремума, можно вывести `w`: 

![Точки экстремума Q(X)](images/img_12.png)

Это значение `w` и будет оптимальным.

## Проблемы нахождения оптимальных весов `w` аналитическим способом:
* Необратимость матрицы `X^T X`
* Вычислительная сложность

## Другое решение: L2-регуляризация 
Устраняет первую проблему: необратимость матрицы.
Единичная матрица `E` обратимая, 
то есть при прибавлении ее с некоторым коэффициентом лямбда
к изначальной матрице
сумма будет также обратимой:

![L2 регуляция](images/img_13.png)

Для корректного поиска оптимальных весов `w` 
при помощи L2-регуляризации необходимо модифицировать функцию риска `Q(X)`

![Q(X) с L2-регуляцией](images/img_14.png)

## Построение модели
### Параметры и гиперпараметры
Параметры: 
* Оптимизируются во время обучения 
* Зависят от тренировочной выборки

Гиперпараметры: 
* Фиксируются до обучения
* Зависят от валидационной выборки

### Этапы построение модели
1. Тренировка 
2. Валидация 
3. Тест 
